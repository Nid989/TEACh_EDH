{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLXwJqbjtPho"
      },
      "outputs": [],
      "source": [
        "!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7 guardrail-ml==0.0.12 tensorboard\n",
        "!apt-get -qq install poppler-utils tesseract-ocr\n",
        "!pip install -q unstructured[\"local-inference\"]==0.7.4 pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAMzy_0FtaUZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    HfArgumentParser,\n",
        "    TrainingArguments,\n",
        "    pipeline,\n",
        "    logging,\n",
        ")\n",
        "from peft import LoraConfig, PeftModel, get_peft_model\n",
        "from trl import SFTTrainer\n",
        "from guardrail.client import (\n",
        "    run_metrics,\n",
        "    run_simple_metrics,\n",
        "    create_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ib_We3NLtj2E"
      },
      "outputs": [],
      "source": [
        "# Used for multi-gpu\n",
        "local_rank = -1\n",
        "per_device_train_batch_size = 4\n",
        "per_device_eval_batch_size = 4\n",
        "gradient_accumulation_steps = 1\n",
        "learning_rate = 2e-4\n",
        "max_grad_norm = 0.3\n",
        "weight_decay = 0.001\n",
        "lora_alpha = 16\n",
        "lora_dropout = 0.1\n",
        "lora_r = 64\n",
        "max_seq_length = None\n",
        "\n",
        "# The model that you want to train from the Hugging Face hub\n",
        "model_name = \"meta-llama/Llama-2-7b-hf\"\n",
        "\n",
        "# Fine-tuned model name\n",
        "new_model = \"llama-2-7b-DH\"\n",
        "\n",
        "# Activate 4-bit precision base model loading\n",
        "use_4bit = True\n",
        "\n",
        "# Activate nested quantization for 4-bit base models\n",
        "use_nested_quant = False\n",
        "\n",
        "# Compute dtype for 4-bit base models\n",
        "bnb_4bit_compute_dtype = \"float16\"\n",
        "\n",
        "# Quantization type (fp4 or nf4)\n",
        "bnb_4bit_quant_type = \"nf4\"\n",
        "\n",
        "# Number of training epochs\n",
        "num_train_epochs = 1\n",
        "\n",
        "# Enable fp16 training, (bf16 to True with an A100)\n",
        "fp16 = False\n",
        "\n",
        "# Enable bf16 training\n",
        "bf16 = False\n",
        "\n",
        "# Use packing dataset creating\n",
        "packing = False\n",
        "\n",
        "# Enable gradient checkpointing\n",
        "gradient_checkpointing = True\n",
        "\n",
        "# Optimizer to use, original is paged_adamw_32bit\n",
        "optim = \"paged_adamw_32bit\"\n",
        "\n",
        "# Learning rate schedule (constant a bit better than cosine, and has advantage for analysis)\n",
        "lr_scheduler_type = \"cosine\"\n",
        "\n",
        "# Number of optimizer update steps, 10K original, 20 for demo purposes\n",
        "max_steps = -1\n",
        "\n",
        "# Fraction of steps to do a warmup for\n",
        "warmup_ratio = 0.03\n",
        "\n",
        "# Group sequences into batches with same length (saves memory and speeds up training considerably)\n",
        "group_by_length = True\n",
        "\n",
        "# Save checkpoint every X updates steps\n",
        "save_steps = 10\n",
        "\n",
        "# Log every X updates steps\n",
        "logging_steps = 1\n",
        "\n",
        "# The output directory where the model predictions and checkpoints will be written\n",
        "output_dir = \"./llama-2-7b-DH\"\n",
        "\n",
        "# Load the entire model on the GPU 0\n",
        "device_map = {\"\": 0}\n",
        "\n",
        "# Visualize training\n",
        "report_to = \"tensorboard\"\n",
        "\n",
        "# Tensorboard logs\n",
        "tb_log_dir = \"./llama-2-7b-DH/logs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJXpOgBFuSrc"
      },
      "outputs": [],
      "source": [
        "def load_model(model_name):\n",
        "    # Load tokenizer and model with QLoRA configuration\n",
        "    compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
        "\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=use_4bit,\n",
        "        bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
        "        bnb_4bit_compute_dtype=compute_dtype,\n",
        "        bnb_4bit_use_double_quant=use_nested_quant,\n",
        "    )\n",
        "\n",
        "    if compute_dtype == torch.float16 and use_4bit:\n",
        "        major, _ = torch.cuda.get_device_capability()\n",
        "        if major >= 8:\n",
        "            print(\"=\" * 80)\n",
        "            print(\"Your GPU supports bfloat16, you can accelerate training with the argument --bf16\")\n",
        "            print(\"=\" * 80)\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        device_map=device_map,\n",
        "        quantization_config=bnb_config\n",
        "    )\n",
        "\n",
        "    model.config.use_cache = False\n",
        "    model.config.pretraining_tp = 1\n",
        "\n",
        "    # Load LoRA configuration\n",
        "    peft_config = LoraConfig(\n",
        "        lora_alpha=lora_alpha,\n",
        "        lora_dropout=lora_dropout,\n",
        "        r=lora_r,\n",
        "        bias=\"none\",\n",
        "        task_type=\"CAUSAL_LM\",\n",
        "    )\n",
        "\n",
        "    # Load Tokenizer\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    tokenizer.padding_side = \"right\"\n",
        "\n",
        "    return model, tokenizer, peft_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QkZ-p5uvTjG"
      },
      "outputs": [],
      "source": [
        "model, tokenizer, peft_config = load_model(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ft2za_TFaVbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKo3C1fRbnSi"
      },
      "outputs": [],
      "source": [
        "from datasets import load_from_disk\n",
        "train_dataset = load_from_disk('/path/to/dataset')\n",
        "valid_dataset = load_from_disk('/path/to/dataset')\n",
        "# Datasets should have 'dialog' and 'gameplan_prediction' as column names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "muz4daHNbanT"
      },
      "outputs": [],
      "source": [
        "def format_dataset(sample):\n",
        "    instruction = f\"<s>[INST] You are given a dialog between a Commander and a Driver, where the Commander gives instructions and Driver does as instructed. Your task is to provide all the (action, object) sequences required to complete all the tasks mentioned in the dialog.\"\n",
        "    context = f\"Here's the dialog: {sample['dialog']}\"\n",
        "    response = f\" [/INST] {sample['gameplan_prediction']}\"\n",
        "    # join all the parts together\n",
        "    prompt = \"\".join([i for i in [instruction, context, response] if i is not None])\n",
        "    return prompt\n",
        "\n",
        "# template dataset to add prompt to each sample\n",
        "def template_dataset(sample):\n",
        "    sample[\"text\"] = f\"{format_dataset(sample)}{tokenizer.eos_token}\"\n",
        "    return sample\n",
        "\n",
        "\n",
        "train_data = train_dataset.map(template_dataset, remove_columns=list(train_dataset.features))\n",
        "validation_data = valid_dataset.map(template_dataset, remove_columns=list(valid_dataset.features))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFteTeiidKhR"
      },
      "outputs": [],
      "source": [
        "generator = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "text = \"INST] You are given a dialog between a Commander and a Driver, where the Commander gives instructions and Driver does as instructed. Your task is to provide all the (action, object) sequences required to complete all the tasks mentioned in the dialog.Here's the dialog:  Hello, what are we doing today? <<TURN>>  grab the mug off the table <<TURN>>  by the window <<TURN>>  OKay. <<TURN>>  take it to the sink and wash it <<TURN>>  Okay, what next/ <<TURN>>  Alright. <<TURN>>  clear the sink first <<TURN>>  Okay, all cleared. Putting mug in sink now. <<TURN>>  turn on the water <<TURN>>  Water is on already. <<TURN>>  after you placed in the sink <<TURN>>  claen it and take it to the coffee maker <<TURN>>  *clean <<TURN>>  place in sink <<TURN>>  It won't let me place the cup into the sink. <<TURN>>  turn off water first <<TURN>>  Thank you <<TURN>>  thats what im here for [/INST]\"\n",
        "generator(text, max_length=1024)\n",
        "\n",
        "# train_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Usy6vtIXf02m"
      },
      "outputs": [],
      "source": [
        "training_arguments = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    per_device_train_batch_size=per_device_train_batch_size,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "    optim=optim,\n",
        "    save_strategy=\"no\",\n",
        "    logging_steps=logging_steps,\n",
        "    learning_rate=learning_rate,\n",
        "    fp16=fp16,\n",
        "    bf16=bf16,\n",
        "    max_grad_norm=max_grad_norm,\n",
        "    max_steps=max_steps,\n",
        "    warmup_ratio=warmup_ratio,\n",
        "    group_by_length=group_by_length,\n",
        "    lr_scheduler_type=lr_scheduler_type,\n",
        "    push_to_hub=True,\n",
        "    report_to=\"tensorboard\"\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=train_data,\n",
        "    peft_config=peft_config,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        "    packing=packing,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.model.save_pretrained(output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TEGmDhqWaazb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}